<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Daily (?) Complaints (?)]]></title>
  <link href="http://zmwangx.github.io/atom.xml" rel="self"/>
  <link href="http://zmwangx.github.io/"/>
  <updated>2014-11-02T17:28:20-08:00</updated>
  <id>http://zmwangx.github.io/</id>
  <author>
    <name><![CDATA[Zhiming Wang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Vobcopy, Dvdbackup, Etc.]]></title>
    <link href="http://zmwangx.github.io/blog/2014/11/02/vobcopy-dvdbackup-etc/"/>
    <updated>2014-11-02T15:06:07-08:00</updated>
    <id>http://zmwangx.github.io/blog/2014/11/02/vobcopy-dvdbackup-etc</id>
    <content type="html"><![CDATA[<p>A few days ago, I was cloning my entire Audio CD and DVD collection, and reported some of the findings in <a href="http://zmwangx.github.io/blog/2014/10/26/audio-cd-slash-dvd-to-iso-image-on-os-x/">this post</a>. As said, the most important commands are</p>

<pre><code>hdiutil makehybrid -iso -joliet -o AUDIO_CD_NAME.iso SOURCE
</code></pre>

<p>for Audio CDs and</p>

<pre><code>hdiutil makehybrid -udf -o DVD_NAME.iso SOURCE
</code></pre>

<p>for DVDs.</p>

<p>Those alone don&rsquo;t finish the story. I also tried other things and unfortunately encountered problems. I was too busy to report back then, but now I&rsquo;ll summarize some of the findings.</p>

<hr />

<p>For one thing, <code>hdiutil makehybrid</code> might fail, issuing an &ldquo;Operation not permitted&rdquo; for no obvious reason. This could even happen when you work with the Disk Utility GUI (for which I once got a &ldquo;Permission denied&rdquo;). Even <code>sudo</code> didn&rsquo;t help in my case. However, I was able to <strong>circumvent the problem with the root shell</strong> (I won&rsquo;t tell you how to enter the root shell — you need to at least have that amount of knowledge about the root shell before you are given the key). Not sure why. Just keep in mind that the root shell might help (that&rsquo;s also a general, albeit dangerous, advice for life).</p>

<hr />

<p>Next onto grabbing the raw VOB.</p>

<p><code>vobcopy</code> is pretty sweet, but at least for me it had one huge problem. When I tried to copy a single title, say title #2 with</p>

<pre><code>vobcopy --title-number TITLE_NUMBER -i SOURCE
</code></pre>

<p>other titles got copied, too. I didn&rsquo;t have enough samples to test out, but presumably it&rsquo;s because the problematic DVD has a structure like this:</p>

<p><img src="http://i.imgur.com/HTgmwQL.png" alt="problematic DVD title structure" /></p>

<p>Anyway, no matter I <code>vobcopy</code> title 01, 02, or 03, the result was the same — the whole thing. That&rsquo;s pretty stupid. I don&rsquo;t know if it counts as a bug or unfinished feature. Definitely not cool.</p>

<p>(One cool thing about <code>vobcopy</code>: as long as you complied with <code>libdvdread</code>, you can create a fully decrypted version of the DVD with</p>

<pre><code>vobcopy --mirror -i SOURCE
</code></pre>

<p>Of course, to get an iso image out of the decrypted mirror, you run the <code>hdiutil makehybrid -udf</code> command given above.)</p>

<hr />

<p>So <code>vobcopy</code> is dead (for copying specific titles in unfortunate DVDs). What&rsquo;s next?</p>

<p>There&rsquo;s <code>dvdbackup</code>. The man page is good, and <a href="https://wiki.archlinux.org/index.php/dvdbackup#A_single_title">ArchWiki</a> is even better (<em>ArchWiki is awesome!</em>), providing you cookbook solutions of combining the power of <code>dvdbackup</code> and <code>dvdauthor</code> (cookbooks are nice when dealing with unexciting technologies like DVD). In fact, <code>dvdbackup</code> alone is enough for extracting the VOBs of relatively small titles (&lt; 1GiB):</p>

<pre><code>dvdbackup -i SOURCE -o VOB_TARGET_DIR -t TITLE_NUMBER -n TITLE_NAME
</code></pre>

<p>then grab your title-specific VOB in <code>VOB_TARGET_DIR/TITLE_NAME/VIDEO_TS</code>. Unlike <code>vobcopy</code>&rsquo;s <code>-n/--title-number</code> option, <code>dvdbackup</code>&rsquo;s <code>-t/--title</code> option does it right, trimming everything else. However, there&rsquo;s a problem when the title is larger than 1 GiB — then <code>dvdbackup</code> will split the VOB into several 1 GiB max pieces, and there&rsquo;s no way to disable this (since <code>dvdbackup</code> is targeting a DVD player — ancient technology — rather than <code>mpv</code> or whatever). What&rsquo;s sadder is that I can&rsquo;t seem to combine the split VOBs with FFmpeg stream copy — <code>pcm_dvd</code> audio always gets converted to <code>mp2</code> and fails when I use <code>-c copy</code>. I&rsquo;m not a codec expert, but I suppose this is due to the fact that <code>pcm_dvd</code> isn&rsquo;t a supported encoding codec of FFmpeg (at least not my FFmpeg):</p>

<pre><code>&gt; ffmpeg -codecs | grep pcm_dvd
D.A..S pcm_dvd              PCM signed 20|24-bit big-endian
</code></pre>

<p><code>D</code> is for &ldquo;Decoding supported&rdquo;, <code>A</code> is for &ldquo;Audio codec&rdquo;, <code>S</code> is for &ldquo;Lossless compression&rdquo; — no encoding support. By the way, my FFmpeg is <code>brew</code>ed with the options <code>--with-fdk-aac</code>, <code>--with-ffplay</code>, <code>--with-freetype</code>, <code>--with-libass</code>, <code>--with-libbluray</code>, <code>--with-openjpeg</code>, <code>--with-openssl</code>, <code>--with-x265</code>:</p>

<pre><code>&gt; \ffmpeg -version
ffmpeg version 2.4.2 Copyright (c) 2000-2014 the FFmpeg developers
built on Oct 19 2014 14:09:36 with Apple LLVM version 6.0 (clang-600.0.51) (based on LLVM 3.5svn)
configuration: --prefix=/usr/local/Cellar/ffmpeg/2.4.2 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-nonfree --enable-hardcoded-tables --enable-avresample --enable-vda --cc=clang --host-cflags= --host-ldflags= --enable-libx264 --enable-libfaac --enable-libmp3lame --enable-libxvid --enable-libfreetype --enable-libass --enable-ffplay --enable-libfdk-aac --enable-openssl --enable-libx265 --enable-libopenjpeg --disable-decoder=jpeg2000 --extra-cflags='-I/usr/local/Cellar/openjpeg/1.5.1_1/include/openjpeg-1.5 '
libavutil      54.  7.100 / 54.  7.100
libavcodec     56.  1.100 / 56.  1.100
libavformat    56.  4.101 / 56.  4.101
libavdevice    56.  0.100 / 56.  0.100
libavfilter     5.  1.100 /  5.  1.100
libavresample   2.  1.  0 /  2.  1.  0
libswscale      3.  0.100 /  3.  0.100
libswresample   1.  1.100 /  1.  1.100
libpostproc    53.  0.100 / 53.  0.100
</code></pre>

<p>Maybe I missed some <code>--enable</code>.</p>

<p>Sorry for the digression. So, it&rsquo;s not possible to stream-copy-concat the VOBs with FFmpeg. (In fact, since audio quality is not that important — you won&rsquo;t be able to tell 256k AAC from lossless anyway, especially when you are focusing on the video, so you can always transcode <code>pcm_dvd</code> into 256k AAC with <code>-c:a libfdk_aac -b:a 256k</code>. <code>mpeg2video</code> is an encoding supported codec so stream copy works fine. Or you may also use <code>flac</code> or whatever encoding-supported lossless codec.) However, if you insist on getting the original <code>pcm_dvd</code>, there is a way, an ugly way. You&rsquo;ve gotta be creative here. <a href="https://wiki.archlinux.org/index.php/dvdbackup#A_single_title">ArchWiki</a> already provides a cookbook solution on how to use <code>dvdbackup</code> and <code>dvdauthor</code> to create a DVD with a selected title. And <code>vobcopy</code> can copy the entire thing just fine, without the 1 GiB limit (make sure to use the <code>-l/--large-file</code> option if the size is greater than 2 GiB). Therefore, you can create a DVD with selected title from the original DVD, then <code>vobcopy</code> from the new DVD. This is insane, but it works, I&rsquo;ve tested that. <strong>Note, however, that timestamps might be wrong with <code>vobcopy</code>, so the VOB runs just fine linearly but might run into problems when you seek.</strong> Therefore, FFmpeg is still the way to go. Or maybe you can do it right with one click using some closed source software ☹ — I&rsquo;ve heard about success stories with the long ceased DVD Decrypter Windows project. In reality, I guess only people with theoretical interest or OCD will ever do this — FLAC or AAC should serve everyone just fine. It should have worked with <code>vobcopy</code> alone, but it doesn&rsquo;t. Hence the workaround.</p>

<hr />

<p>For future reference, I&rsquo;ll translate the ArchWiki cookbook solution here (it&rsquo;s too cookbook itself, specifying paths like <code>~/movie_name</code> and using unnecessary <code>cd</code>) about creating a title-specific DVD from a multi-title DVD (replace <code>SOURCE</code>, <code>VOB_TARGET_DIR</code>, <code>DVD_TARGET_DIR</code>, <code>TITLE_NUMBER</code>, and <code>TITLE_NAME</code> with sane values):</p>

<pre><code>dvdbackup -i SOURCE -o VOB_TARGET_DIR -t TITLE_NUMBER -n TITLE_NAME
dvdauthor -t -o DVD_TARGET_DIR VOB_TARGET_DIR/TITLE_NAME/VIDEO_TS/*.VOB
export VIDEO_FORMAT=NTSC
cd DVD_TARGET_DIR/VIDEO_TS &amp;&amp; dvdauthor -T -o DVD_TARGET_DIR
</code></pre>

<p><code>export VIDEO_FORMAT=NTSC</code> is to avoid the <code>dvdauthor</code> error of &ldquo;no default video format, must explicitly specify NTSC or PAL&rdquo; (I&rsquo;m not sure about the difference between NTSC and PAL, but I saw NTSC printed on my DVD, so I used it). And there you go, a shiny new DVD filesystem located in <code>DVD_TARGET_DIR</code>. (Note that unlike <code>vobcopy</code>, <code>dvdbackup</code> doesn&rsquo;t feature a nice progress bar even when <code>-v/--verbose</code> and <code>-p/--progress</code> are specified.) Then you can</p>

<pre><code>vobcopy -l DVD_TARGET_DIR
</code></pre>

<p>if you&rsquo;d like to. Recall that timestamps might be wrong, sadly.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fun]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/29/fun/"/>
    <updated>2014-10-29T11:26:29-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/29/fun</id>
    <content type="html"><![CDATA[<p>This happened in yesterday&rsquo;s Math 210A lecture.</p>

<blockquote><p>Ravi: I won&rsquo;t be here next Thursday.<br>
Someone: Will there be a lecture?<br>
Ravi: Yeah, Brian Conrad will give a lecture. Don&rsquo;t tell him, he don&rsquo;t know this yet.</p></blockquote>

<p>&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Drive — No Selective Subfolder Sync?]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/28/google-drive-no-selective-subfolder-sync/"/>
    <updated>2014-10-28T20:49:24-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/28/google-drive-no-selective-subfolder-sync</id>
    <content type="html"><![CDATA[<p>Up to this point I&rsquo;ve been using Google Drive as an online backup service, and uploads files mostly manually, although I do sync <code>~/img</code> with the client.</p>

<p><strong>Aside.</strong> Google Drive, OneDrive, etc. don&rsquo;t work with symlinks. Wanna keep your stuff free and duplicate-free yet still synced to the servers? Use <code>rsync</code> to automatically reproduce your folder structure with hard links:</p>

<pre><code>rsync -avzP --delete --link-dest=SOURCE/ SOURCE DESTINATION
</code></pre>

<p>e.g.,</p>

<pre><code>rsync -avzP --delete --link-dest=~/img/ ~/img/ ~/sync/GoogleDrive/img/
</code></pre>

<p>automatically reproduces my <code>~/img</code> in the <code>img</code> directory under Google Drive&rsquo;s root, yet every file in the <code>~/img</code> tree is replaced by hard links to the original file, so the new structure within Google Drive takes little additional space — for the directories only.</p>

<p>That doesn&rsquo;t solve every problem though, as you will see shortly. <em>End of aside.</em></p>

<p>So, up to this point I’ve mostly used Google Drive as an online backup service by manually uploading (huge) stuff. But at some point I’m gonna automate parts of the uploading. As it turns out, I can keep some smaller video files on my hard drive; other bigger monsters (like movies, TV shows, etc., especially a lot of 1080i Transport Streams directly from TV broadcasts) are uploaded and then moved to external drives. Some of the smaller files, including things downloaded from YouTube, live in <code>~/vid/etc</code>, and I want to sync this folder to Google Drive. What&rsquo;s shocking is that this is not possible with the Google Drive client — it only allows selective syncing of the top level folders. Let me repeat this:</p>

<p><strong>The Google Drive client only allows selective syncing of the <em>top level folders</em>.</strong></p>

<p>This is <em>insane</em>. It’s almost 2015. Everyone supports this — Dropbox, Microsoft, Box, even Baidu. Google Drive launched on April 24, 2012, that’s 2.5 years ago. <a href="https://productforums.google.com/forum/#!topic/drive/Gs2w1BL-B9U">This thread</a> on Google Drive Forum, “Ability to sync only selected sub folders”, was posted on August 27, 2012, and has garnered 139 replies. They are ignored by the developers, and the accepted “answer” is to utilize Google Drive’s assign-one-file/folder-to-multiple-folders feature to create a special “sync” directory. Okay, that’s a stupid hard link solution on the server side. Okay, if that works… <em>No</em>. “Hard links on the server side” cannot bear different names; so what if I want to sync, say, both <code>vid/etc</code> and <code>aud/etc</code>? Whoops. So I also have to do all sorts of ugly renaming. NO, GOOGLE, NO, I won&rsquo;t accept that much trouble.</p>

<p>This kind of insanity makes me wander:</p>

<p><strong>Do the Google Drive developers use Google Drive themselves?</strong></p>

<p>For now I&rsquo;m moving <code>vid/etc</code> to <code>vid_etc</code>. Sigh.</p>

<hr />

<p>There are other problems that I encountered with Google Drive sync today. For one thing, it rejects what I already have and insists on starting from scratch. I mean, say I have uploaded a folder via the web interface, and later wants to keep it in sync (of course that&rsquo;s only possible if it&rsquo;s top level), so I put what I already have there. Nope, Google Drive reports that as a conflict and insists on downloading all the stuff again. Apart from wasted traffic, that also ruins my hard links, so I have to either wipe everything clean on the server side and reupload, or redownload everything and redo all the hard-linking after the download finishes. Either way, very annoying. I opted for the first one. (I later empirically confirmed that OneDrive could handle this situation.)</p>

<p>There are other problems that don&rsquo;t pop right off my mind. Anyway, the gist is,</p>

<p><strong>Google Drive is not yet sync-ready for power users (maybe even laymen).</strong></p>

<hr />

<p>Then, is OneDrive perfect? No. I know it recently went unlimited, but there’s one major annoyance: the speed. Stanford’s Ethernet speed is almost 1 Gbps UL/DL, but the OneDrive client tops out at about 2 MBps. The web interface isn’t much better. Google Drive is a lot faster than that, which makes it a good backup service for manual uploading. Anyway, maybe OneDrive will improve over time; yesterday they delivered an update to OneDrive.app, and at least it finally works.</p>

<p>OneDrive also boasts no file status indicators on OS X, which everyone else in the industry has. That’s not a show-stopper though, if you just use it as a backup service.</p>

<hr />

<p>What about Dropbox? Dropbox is a truly awesome sync-ready service, but it is at the same time pretty expensive compared to others. Also, since I use Dropbox as a sync service, it must be up at all times and constantly indexing, so I’m really cautious with what I put there to avoid unnecessary cycles and startup time.</p>

<hr />

<p>Everything is broken in one way or another. Sigh. Let&rsquo;s hope that OneDrive improves a lot in the coming months; if it&rsquo;s stable enough and the speed gets some boost, I&rsquo;ll cancel my Google Drive subscription. I am a Google supporter and Microsoft hater, but a service that <em>works</em> is more important than ideology.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mou 1.0 Fundraiser: Goal Reached]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/28/mou-1-dot-0-fundraiser-goal-reached/"/>
    <updated>2014-10-28T01:57:06-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/28/mou-1-dot-0-fundraiser-goal-reached</id>
    <content type="html"><![CDATA[<p>A week ago I wrote a post <a href="blog/2014/10/20/help-mou-hit-1-dot-0/"><em>Help Mou hit 1.0</em></a>. Today, I&rsquo;m delighted to find out that Mou has reached its goal, $20,000, half way into the fundraiser.</p>

<p><img src="http://i.imgur.com/vM298t5.png" alt="Mou hit its goal on Indiegogo" /></p>

<p>So what do I expect from 1.0? Most importantly,</p>

<ul>
<li>CommonMark support, especially GFM fenced code block and saner nested structures;</li>
<li>Custom Markdown engine (I would like to call <a href="https://github.com/jgm/CommonMark"><code>stmd</code></a>).</li>
</ul>


<p>Whatever the case, Emacs is still my best friend.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OneDrive Goes Unlimited]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/27/onedrive-goes-unlimited/"/>
    <updated>2014-10-27T09:44:51-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/27/onedrive-goes-unlimited</id>
    <content type="html"><![CDATA[<p><strong>10/28/2014 Update:</strong></p>

<p>Yesterday Microsoft pushed an update to OneDrive.app to MAS. After uninstalling, reinstalling, and wiping the 10 GB folder I&rsquo;d like to sync (that&rsquo;s for photos; I upload videos via the web interface) on both client and server sides, it actually began to work. The speed was around 1 MB/s during my last sync of 10 GB worth of data. Not fast, but I will be fairly satisfied if it can keep up with that speed. Time will tell.</p>

<hr />

<p>The OneDrive team just <a href="https://blog.onedrive.com/office-365-onedrive-unlimited-storage/">announced on their blog</a> that</p>

<blockquote><p>Today, storage limits just became a thing of the past with Office 365. Moving forward, all Office 365 customers will get unlimited OneDrive storage at no additional cost.</p></blockquote>

<p>Hell, I hate Microsoft, but <strong>I have to say that this is big</strong>. OneDrive might not be the first to offer unlimited cloud storage (not sure), but it is certainly the first one to roll it out on such a grand scale. Remember, Office 365 is just $99.99 a year. OneDrive might not be the best cloud storage service, especially for OS X customers, but unlimited is unlimited — in comparison, I pay Google $9.99 a month for 1 TB.</p>

<p>Microsoft products are indeed pure crap on a Mac. Office for Mac 2011 is horrible (speed and bloat aside, some features are simply not implemented — try to import a UTF-8 CSV into Excel, all non-ASCII characters become underscores; Microsoft’s response was that Unicode import was not implemented yet). OneDrive.app is slow like crawl, and it never finishes syncing — always stuck on the last few megabytes, eating up 100% CPU. Thank god I only use it for backups. The web interface is okay, although Google Drive is faster — blazing fast, I can easily upload with 20+MB/s. But again, <strong>unlimited is unlimited.</strong></p>

<p>Microsoft is opening a new chapter of cloud storage. In today’s world, we have so many huge video files, so storage limit should indeed be something of the past. This is a smart move for Microsoft — when you have, say, 100 TB up there (which seems very far at this moment, but what if all contents go 4K), and if competitors don’t offer comparable plans, then you are stuck with Microsoft. And Office. Oh my god, Microsoft Office must die.</p>

<p>Of course I don’t want to be stuck with Microsoft, so I’m looking at how Google and Apple will handle this. Google ought to offer more affordable plans, preferably also unlimited. (My 1Password still has it that I purchased Office for Mac University 2011 on Nov 12, 2012 for $99.99. That turned into a free 4-year Office 365 subscription, which contains 60 world minutes of Skype per month, 1 TB of OneDrive — oh, now it’s about to go unlimited. All for $99.99. In comparison, Google charges me $119.88 per year.) Apple wants you to save everything to iCloud, and it introduced iCloud Drive and Cloud Kit this year — but plans still start at 5 GB and tops out at 1 TB, seriously? Dude, you sell top notch hardware with huge profits; why don’t you pay your customers back by offering better cloud storage — that’s also better for iCloud.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert Audio CD/DVD to ISO Image on OS X]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/26/audio-cd-slash-dvd-to-iso-image-on-os-x/"/>
    <updated>2014-10-26T23:29:47-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/26/audio-cd-slash-dvd-to-iso-image-on-os-x</id>
    <content type="html"><![CDATA[<p>Today it occurred to me that I should make clones of my audio CDs (as stand-alone ISO images, I mean, not just rsyncing the AIFFs to subdirectories in <code>~/aud/lossless</code>). One can never have too many backups.</p>

<p>Of course I could simply pack the aforementioned directories with AIFFs into ISOs — that’s not impressive. The end result might actually be the same, but I want to make the clones directly from the original CDs. It turns out that this is not so simple with the Disk Utility GUI — unlike DVDs, the “New Image” option is grayed out for Audio CDs. I’m not sure why, but maybe they want you to just use iTunes to deal with Audio CDs (which works well for all practical purposes — but theoretical curiosity never ends).</p>

<p>So there comes <code>hdiutil</code>. <code>hdiutil</code> and <code>diskutil</code> are the utilities underlying Disk Utility. Unfortunately, so far I know little about them except for simplest things like <code>diskutil list</code>, <code>diskutil mount</code>, <code>hdiutil attach -stdinpass</code>, etc. (I&rsquo;m so ignorant about anything filesystem related!) The <code>hdiutil</code> verb that makes cross-platform CD or DVD is <code>makehybrid</code>, which supports the following filesystem options: <code>-hfs</code> (holy crap, no HFS+ please! Apple ought to replace this thirty-year-old filesystem — ZFS or something better please!), <code>-iso</code>, <code>-joliet</code>, and <code>-udf</code>. For Audio CDs you use <code>-iso</code> and with <code>-joliet</code> extension:</p>

<pre><code>hdiutil makehybrid -iso -joliet -o AUDIO_CD_NAME.iso SOURCE
</code></pre>

<p>where <code>SOURCE</code> can be the mount point, the disk device file, etc. Similarly, although you can create <code>.cdr</code> images from DVDs via the Disk Utility GUI, you can also do it with <code>hdiutil</code> (which is potentially more portable — I’ve never heard a definitive answer of whether renaming <code>.cdr</code> to <code>.iso</code> really cross-platform):</p>

<pre><code>hdiutil makehybrid -udf -o DVD_NAME.iso SOURCE
</code></pre>

<p>This way CSS keys <em>seem</em> to be cloned as well, since I was able to authenticate such a CSS-protected DVD with <code>libdvdread</code>.</p>

<hr />

<p>P.S. I sincerely hope that one day lossless music tracks are no longer distributed through CD-ROMs. So painful — even my Internet speed is more than ten times faster than the <a href="https://en.wikipedia.org/wiki/CD-ROM#Transfer_rates">highest transfer rate</a> available from any CD-ROM. (I’ve heard about some websites distributing lossless music digitally, but that won’t happen to the music I care about in the near future.) I still like physical albums though — a real sense of possession. Maybe they should contain the physical goodies and some sort of access codes?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Disk Visualizer: DaisyDisk]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/26/disk-visualizer-daisydisk/"/>
    <updated>2014-10-26T00:02:22-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/26/disk-visualizer-daisydisk</id>
    <content type="html"><![CDATA[<p>DaisyDisk is a pretty famous name. I’ve heard a lot that DaisyDisk is beautiful, but as a “power user” I always feel ashamed about using a disk analyzer or visualizer (although no one really cares). I’m pretty comfortable with doing most filesystem operations right in the shell, and for other tasks too tedious for the shell (like renaming a bunch of files with no obvious pattern), Finder (equipped with TotalFinder) works just fine.</p>

<p>Today I was trying clean up my drive a bit, as there were only 22GB left. I knew where the main problem lied: a huge number of highres videos lying in <code>~/vid/staging</code>, awaiting renaming and migration to my external drive. Anyway, it would be nice to have some visualization of a detailed breakdown of my disk usage, preferably on any level I want without multiple passes of <code>du</code>. The name DaisyDisk popped up from the cache in my brain, so I headed over to their website to download it.</p>

<p>The result is not disappointing at all. Look at this:</p>

<p><img src="http://i.imgur.com/vyIwSNQ.png" alt="DaisyDisk screen shot" /></p>

<p>Beautiful. Moreover, functional. It indeed gives me a detailed breakdown on any level, within any directory (given enough priviledge). I can also collect items I don’t want and let DaisyDisk clean up for me at once (not surprising for a disk analyzer); this feature isn’t that useful for me since I know exactly where my queues of unorganized items are — <code>~/Downloads</code>, <code>~/aud/staging</code>, <code>~/img/staging</code>, and <code>~/vid/staging</code>.</p>

<p>By the way, DaisyDisk seems to be WinRAR-free. (Rest assured; I’m a good guy and I <em>will</em> purchase a license — these days whether to purchase the website or the MAS version is a headache, though.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OS X Package Receipts]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/25/os-x-package-receipts/"/>
    <updated>2014-10-25T13:26:02-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/25/os-x-package-receipts</id>
    <content type="html"><![CDATA[<p>I just learned something new. Whenever you install a <code>pkg</code> on OS X, OS X stores a receipt of what was installed in <code>/var/db/receipts</code> (I&rsquo;m running OS X 10.9.5 at the time of writing), called a <strong>bom</strong> — bill of materials (I’d rather call it a manifest, whatever). This feature was introduced in NeXTSTEP. From <code>man 5 bom</code>:</p>

<blockquote><p>The Mac OS X Installer uses a file system &ldquo;bill of materials&rdquo; to determine which files to install, remove, or upgrade. A bill of materials, <strong>bom</strong>, contains all the files within a directory, along with some information about each file. File information includes: the file&rsquo;s UNIX permissions, its owner and group, its size, its time of last modification, and so on.  Also included are a checksum of each file and information about hard links.</p></blockquote>

<p><code>man 5 bom</code> is actually badly maintained, as it says &ldquo;The bill of materials for installed packages are found within the package receipts located in /Library/Receipts,&rdquo; whereas those have been migrated to <code>/var/db/receipts</code> a long time ago.</p>

<p><code>.bom</code> files are binary, but you can access the contents via <code>lsbom</code>. For instance, to list the files installed,</p>

<pre><code>lsbom -f /var/db/receipts/org.macports.MacPorts.bom
</code></pre>

<p>Note that the paths printed are always relative to <code>/</code>. See <code>man 1 lsbom</code> for detailed option listing.</p>

<p>(Beware when you try to clean up unwanted packages using the <code>lsbom</code> listing. Packages might overwrite files, so make sure you review the listing first and know what you are doing. &ldquo;Knowing what you are doing&rdquo; is the prerequisite for using <code>sudo</code> anyway.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Charles Munger Donated $65M to KITP]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/24/charles-munger-donated-$65m-to-kitp/"/>
    <updated>2014-10-24T16:41:36-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/24/charles-munger-donated-$65m-to-kitp</id>
    <content type="html"><![CDATA[<p>Today&rsquo;s news has it that Charles Munger made a $65 million donation to KITP at UCSB. See for instance <a href="http://nyti.ms/1D4zg24">this article</a> on NYT. Of course I didn&rsquo;t learn it from NYT (I&rsquo;m generally sick of any news other than math, physics, or IT-related ones). I learned it from <a href="http://www.math.columbia.edu/~woit/wordpress/?p=7247">Not Even Wrong</a> instead (of course I don&rsquo;t agree with Woit, but some of his links are nice).</p>

<p>I have no interest whatsoever in the business world, so I have no idea about Warren Buffett&rsquo;s business partners (although I&rsquo;m still worldly enough to know Warren Buffett). However, the name Charles Munger sounded surprisingly familiar. After reading the sentence</p>

<blockquote><p>Mr. Munger has frequently donated big sums to schools like Stanford and the Harvard-Westlake School.</p></blockquote>

<p>from the NYT article linked above, it finally hit me that Mr. Munger is the donor of the Munger Graduate Residence here at Stanford. Munger is really nice, much better than our undergrad residences AFAIK (location-wise Roble is still unbeatable for mathematicians and physicists, although Munger still kicks EV&rsquo;s ass).</p>

<p>I&rsquo;m glad to see more and more entrepreneurs funding physics, especially theoretical physics, whether they understand it or not. (<strong>Aside:</strong> Even for laypeople theoretical physics is cool isn&rsquo;t it, like the coolest kid in class. I won&rsquo;t comment on whether math is cooler, but breakthrough mathematical work certainly go largely unnoticed in the public, since theoretical physics is the last thing that laypeople can &ldquo;vaguely understand&rdquo;. Do some name searches on Google to see how math and physics play out in the limelight — hint:</p>

<ul>
<li>Gauss — 4,130,000 results;</li>
<li>Euler — 855,000 results;</li>
<li>Newton — 13,200,000 results;</li>
<li>Einstein — 6,330,000 results.</li>
</ul>


<p>End of aside.) Engaging in physics is plain better than engaging in some questionable philanthropy. (Have you heard that Gates Foundation invested in G4S, the largest private military and security company in the world? I’m not sure about the details — I once read that off a bathroom flyer — but that’s definitely interesting philanthropy.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ripping Copy-protected DVD With Mpv]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/23/ripping-copy-protected-dvd-with-mpv/"/>
    <updated>2014-10-23T20:03:22-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/23/ripping-copy-protected-dvd-with-mpv</id>
    <content type="html"><![CDATA[<p><strong><em>10/25/2014 update:</em></strong></p>

<p>I&rsquo;m such an idiot. <code>vobcopy</code> is the real, hassel-free way to go.</p>

<pre><code>brew install vobcopy
</code></pre>

<p>Then, with the DVD mounted,</p>

<blockquote><p><strong>vobcopy</strong> without any options will copy the title with the most chapters into files of 2GB size into the current working directory.</p></blockquote>

<p>Of course there are a ton of options, but I generally hate to browse through options unless I have to, so I&rsquo;m happy with calling without argument.</p>

<hr />

<p>Yesterday I was trying to rip a music video off a newly released DVD from Japan. I knew very little about how DRM (in this case, CSS) actually works and how to break it. I tried to operate directly on the VOB file with <code>ffmpeg</code> or <code>mpv</code> but both failed with a lot of header errors — I suppose more files than the VOB are required for authentication? Whatever, maybe I’ll learn the details in the future, but I don’t see the need since DVD is an outdated technology anyway.</p>

<p>So, can we proceed from here? Most certainly. I noticed that although <code>mpv</code> won’t let me play a single VOB, I can simply hand it the DVD mount point, and it will play the whole DVD seamlessly. <strong>Caution:</strong> <code>mpv</code> needs to be compiled with <code>libdvdnav</code> and <code>libdvdread</code>! With brew you just do</p>

<pre><code>brew install mpv --with-libdvdnav --with-libdvdread
</code></pre>

<p>For better performance and backup, I first cloned the DVD into a <code>.cdr</code> image (DVD/CD-R Master Image) using Disk Utility (I&rsquo;ve never tried creating/cloning image with <code>diskutil</code> CLI, so nothing to report on that). Then I mount the image, say the mount point is <code>/Volumes/UPBX_80165</code>. As said I can hand that mount point to <code>mpv</code> and it simply works, but how about extracting the MPEG-2 video stream? The <code>--stream-capture=&lt;filename&gt;</code> option is there just for you. In principle <code>--stream-dump=&lt;filename&gt;</code> should also work, but without monitoring the output and controlling where to end, I’m not sure if it will ever terminate itself when reading from a DVD (when I stream captured the DVD it just kept repeating itself until I explicitly quit with <code>q</code>). So that&rsquo;s it:</p>

<pre><code>mpv --stream-capture=dump.mpg /Volumes/UPBX_80165
</code></pre>

<p>Then you can torture the <code>dump.mpg</code> with <code>ffmpeg</code> however you want. The most obvious thing is to cut out the music video part, and put into a new container like MPEG-TS. Or transcode it to H.264 for your iPhone. The nice thing about <code>dump.mpg</code> is that, unless I got it wrong, there&rsquo;s no quality loss here — the only thing you got rid of is that goddamn DRM.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get Rolling]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/21/get-rolling/"/>
    <updated>2014-10-21T11:40:14-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/21/get-rolling</id>
    <content type="html"><![CDATA[<p>Yesterday, on an internet forum, I saw someone’s signature, which translates to</p>

<blockquote><p>Don’t even get started if you know you can&rsquo;t know from the beginning that you won&rsquo;t make it to the very end.</p></blockquote>

<p>This seems justified — persistence is the key to success; why even bother if you know you’ll fail? However, I have to profoundly disagree with this, and even dedicate a blog post to discussing this problem.</p>

<p>The problem here is, the real world is much more complicated than the idealized world found in various quotes about persistence. Most of the time you have absolutely no clue where which road is leading, unless you embark on the journey, clueless. As for me, fortunately I knew I was gonna be a mathematician/physicist ever since elementary school, so the roadmap is sorta clear on the grand scale. Still, all those tiny building blocks for the ultimate goal are confusing, and even more so for things hardly related to the ultimate goal, for instance, coding, which is just a hobby and a way to simplify life — it has simplified my life in some sense, but has itself complicated my life in other ways (your life inevitably becomes more complicated when you know more and want to find out even more).</p>

<p>And sometimes you are bound to fail — I know my code is shitty, for instance, but if I don’t get rolling, I won’t even have a working (albeit shitty) version that barely meets my needs. As another example, I was looking for a way to share and archive some photos. I started with <a href="http://apinkarchive.wordpress.com/">WordPress</a>, which turned out to be more formal and tiring than I’d thought. Then I ran a <a href="http://chorongmemories.tumblr.com/">Tumblr microblog</a>, which was great, but has certain limitations that in the end prevents it from being damn useful for myself, so in the end I went onto “indefinite hiatus.” In both cases I never declared that the thing was permanent — I was careful to say that the blogs were experimental, and I moved on when I found something better, or when they were no longer helping me. Yesterday I started yet another experiment, a <a href="http://apinkpcr.tistory.com">Tistory blog</a>. It is a random move triggered by something unexpected; the South Korean blogging platform is not that great, but at least it provides acceptable API access, and more importantly, I’ve got complete infrastructure built around the API to scrape photos, so it’s easy to build on top of that to automate things. It is also experimental. Again I’m not sure I long I can keep it up, but at least I’m happy with it for the time being. Being happy at the time being is the most important goal for hobbies.</p>

<p>Choices are hard. Especially in today’s world, tools in every discipline are constantly improving, be it math, physics, programming, photography, blogging, or whatever. If you research over and over until you find “the perfect tool”, or “the perfect platform” (hint: the rank is constantly changing), you’re stuck on the first step to anywhere. In fact, reading other people’s blogs, for example, are not enough to learn what is the best — you need to at least have some working knowledge to even decide which tool or platform is more suitable for you. Therefore, the most sensible thing to do is to do a little bit of research (combined with your gut feeling), pick up something that makes you feel good at the moment, and immediately get rolling. Well, of course you need some research, otherwise you’re just kidding yourself; doing <code>&gt;&gt;&gt; import this</code> in python tells you:</p>

<blockquote><p>Now is better than never.<br>
Although never is often better than <em>right</em> now.</p></blockquote>

<p>Then, when you have more experience and know what’s wrong with your original choice, correct it or trash it. There’s nothing wrong with abandoning dated crap, hopping bandwagons, or whatever; that’s the nature of change and improvement, and the most sensible thing for someone as busy as you are.</p>

<p>Up till now I&rsquo;ve been talking about tools and platforms, so maybe it seems that I&rsquo;m attacking the straw man — you may argue that the original quote is not about what tools or platforms you use, but rather, what you try to accomplish with the tools or platforms. Okay, what about the grander things in life, like mathematical research, like <em>the final theory</em>? Well, similar. I’ll quote Ravi here,</p>

<blockquote><p>…mathematics is so rich and infinite that it is impossible to learn it systematically, and if you wait to master one topic before moving on to the next, you’ll never get anywhere. Instead, you’ll have tendrils of knowledge extending far from your comfort zone. Then you can later backfill from these tendrils, and extend your comfort zone; this is much easier to do than learning “forwards”.</p></blockquote>

<p>Ravi is always hinting at “you should get started with actual research rather than ‘prepare’ yourself”! I can’t reckon that since I’ve yet to follow Ravi’s advice, but the thinking here is crystal clear. <strong>You shouldn’t be afraid of failure; you shouldn’t be afraid of being “not prepared enough”; you shouldn’t be afraid of getting started.</strong> Speaking of a final theory, I’m pretty sure I’m bound to fail, I’m pretty sure I won’t see a satisfactory one in my lifetime — the inconvenient truth is that, I have the gut feeling that the ultimate explanation is unfortunately intertwined with consciousness, and we are still far from having the right tools to understand consciousness. According to Feynman, <strong>really knowing something is hard</strong>. It’s hard, so failure is not shameful at all. Those who won’t even get started due to fear of failing or making the wrong choice won’t fail again, since they’ve already failed at the very beginning. So, get rolling.</p>

<p>Yesterday I read <a href="http://www.joelonsoftware.com/articles/fog0000000339.html">Fire and Motion</a> on <em>Joel on Software</em>. Joel’s metaphor is really nice, but he’s essentially conveying very similar ideas.</p>

<hr />

<p>By the way, I wrote this post in Emacs. I don’t know why but I seem to type much faster in Emacs than in Mou. (For Markdown editing <code>markdown-mode</code>, and <code>typo-mode</code>, a minor mode I found today which is useful for inserting smart quotes and smart dashes seamlessly into md articles).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Help Mou Hit 1.0]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/20/help-mou-hit-1-dot-0/"/>
    <updated>2014-10-20T17:37:45-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/20/help-mou-hit-1-dot-0</id>
    <content type="html"><![CDATA[<p>Quick call for <a href="https://www.indiegogo.com/projects/mou-1-0-markdown-editor-on-os-x-for-you">Mou 1.0 fundraiser</a> on Indiegogo. At the time of writing, it has raised $6,178/$20,000, and has 39 days to go (with 21 already passed).</p>

<p>I&rsquo;m actually writing this post in Mou right now. It&rsquo;s far less powerful than Emacs, but when I want preview-on-the-fly, Mou is the Markdown editor to go. Right now it&rsquo;s far from perfect; for instance, GFM fenced blocks (now included in <a href="http://commonmark.org">CommonMark</a>) are not supported, so you get nonsense preview when your code block is fenced rather than indented. (Of course, Mou is even less suitable for editing an Octopress post due to the yaml metadata upfront, but that&rsquo;s not a big deal.)</p>

<p>Let&rsquo;s hope for Mou hitting the 1.0 mark.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello, Octopress!]]></title>
    <link href="http://zmwangx.github.io/blog/2014/10/20/hello-octopress/"/>
    <updated>2014-10-20T16:53:00-07:00</updated>
    <id>http://zmwangx.github.io/blog/2014/10/20/hello-octopress</id>
    <content type="html"><![CDATA[<p>This post marks my transition from Tumblr to Octopress &amp; GitHub Pages.</p>

<p>I&rsquo;ve been microblogging for a while at <a href="http://zshello3.tumblr.com">zshello3.tumblr.com</a> and I liked it. Not because of readers, which I suspect I have none; but there are certainly a huge amount of information I want to dump off my mind. Back in the days I <em>loved</em> my handwritten journals, and I really poured a lot into them. Peers were usually amazed when they saw my journals. These days typing seems to be a more robust solution to keeping my thoughts, especially when the thoughts are mostly technical.</p>

<p>Tumblr is awesome. Compared to WordPress (.com for pedantic people), it is both lightweight and beautiful (you get all the customization for free), so you quickly get to the writing. However, it is not designed for geeks, so</p>

<ul>
<li>Customization is capped at some point;</li>
<li>I had the impression that the Markdown parser is herrendous;</li>
<li>Email publishing is a mightmare, by the way;</li>
<li>Code rendering always falls short — unless I spend a lot of time customizing (I&rsquo;m pretty bad at HTML, CSS, and JS stuff).</li>
</ul>


<p>Speaking of the last point, I&rsquo;ve always been envious of the beautiful code blocks found on Octopress blogs. So here I come!</p>

<p>(Let me give it a try first.)</p>

<figure class='code'><figcaption><span>hello.c</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='C'><span class='line'><span class="cp">#include &lt;stdio.h&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello, Octopress!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Gorgeous. I&rsquo;ll get to the theme customization later. I&rsquo;m actually busy as crazy this week.</p>

<p>Before I close this post, let me also try to embed a random gist I authored yesterday (for brewing):</p>

<div><script src='https://gist.github.com/828fd00bdecd6611cf40.js?file=brew.sh'></script>
<noscript><pre><code>#!/usr/bin/env bash

progname=$(basename &quot;$0&quot;)

function handle_error
{
    if [[ $? != 0 ]]; then
        echo -e &quot;\n${RED}${progname}: error: &#39;$1&#39; failed${RESET}&quot; &gt;&amp;2
        read -s -p &quot;${GREEN}press ENTER to continue, or any other key to quit${RESET}
&quot; -n1 key
        if [[ ${key} != &#39;&#39; ]]; then
            exit 1
        fi
    fi
}

function execute
{
    echo &quot;${GREEN}${BOLD}$1${RESET}&quot;
    eval &quot;$1&quot;
    handle_error &quot;$1&quot;
    echo
}

function latest_bin
{
    ls -d /usr/local/Cellar/$1/*/bin | tail -n1
}

caveats=&quot;${GREEN}${BOLD}Caveats:${RESET}
* Add ${BLUE}/usr/local/opt/coreutils/libexec/gnubin${RESET} to ${BLUE}\$PATH${RESET} for coreutils without g prefix;
* Add ${BLUE}/usr/local/share/zsh/site-functions${RESET} to ${BLUE}\$fpath${RESET} for additional completions;
* ${RED}${MAGENTA}htop${RED} from ${MAGENTA}htop-osx${RED} has been given root priviledge!${RESET}
* See ${BLUE}brew info libmagic${RESET} for how to access its python api;
* The python formula (for python2) also installs setuptools and pip. They can be upgraded without rebrewing python:
      ${BLUE}pip install --upgrade setuptools${RESET}
      ${BLUE}pip install --upgrade pip${RESET}
  pip packages are installed in &#39;{BLUE}/usr/local/lib/python2.7/site-packages${RESET}&#39;. See ${GREEN}https://github.com/Homebrew/homebrew/wiki/Homebrew-and-Python${RESET} for details;
* See ${BLUE}brew info zsh-completions${RESET} for usage and caveats;
* Binaries added to ${BLUE}$HOME/bin${RESET} instead of /usr/local/bin:
    * tar (gnu-tar)
    * awk (gawk)
    * getopt (gnu-getopt)
    * curl (curl)

Remember to drop ${BLUE}https://raw.githubusercontent.com/Homebrew/homebrew/master/Library/Contributions/brew_zsh_completion.zsh${RESET} to somewhere in ${BLUE}\${fpath}${RESET} as ${BLUE}_brew${RESET}!
&quot;

case $1 in
    install)
        ;;
    caveats)
        echo -n &quot;${caveats}&quot; &gt;&amp;2
        exit 0
        ;;
    *)
        echo &quot;${progname}: usage:
${BOLD}${progname} install${RESET}
    install brew and my formulas
${BOLD}${progname} caveats${RESET}
    print caveats&quot; &gt;&amp;2
        exit 1
        ;;
esac

# install brew
execute &#39;ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;&#39;

# make sure ~/bin exists
execute &quot;mkdir -p ${HOME}/bin&quot;

# tap dupes and binary
execute &#39;brew tap homebrew/dupes&#39;
execute &#39;brew tap homebrew/binary&#39;

########## essential stuff ##########
# emacs (a bare bones version first)
execute &#39;brew install emacs&#39;
# coreutils
execute &#39;brew install coreutils&#39;
# wget
execute &#39;brew install wget&#39;
# gsed
execute &#39;brew install gnu-sed --default-names&#39;
# grep
execute &#39;brew install grep --default-names&#39;
# gawk
execute &#39;brew install gawk&#39;
prefix=$(latest_bin gawk)
execute &quot;ln -s ${prefix}/gawk ${HOME}/bin/awk&quot;
# Linux getopt
execute &#39;brew install gnu-getopt&#39;
prefix=$(latest_bin gnu-getopt)
execute &quot;ln -s ${prefix}/getopt ${HOME}/bin&quot;
# python and pip
execute &#39;brew install python&#39;

########## cask ##########
execute &#39;brew tap caskroom/cask&#39;
execute &#39;brew install brew-cask&#39;
execute &#39;brew cask&#39;
# xquartz
execute &#39;brew cask install xquartz&#39;

########## semi-essential stuff ##########
# gtar
execute &#39;brew install gnu-tar&#39;
execute &quot;ln -s /usr/local/opt/gnu-tar/libexec/gnubin/tar ${HOME}/bin&quot;
# ffmpeg
execute &#39;brew install ffmpeg --with-fdk-aac --with-ffplay --with-freetype --with-libass --with-libbluray --with-openjpeg --with-openssl --with-x265&#39;
# mpv
execute &#39;brew tap mpv-player/mpv&#39;
execute &#39;brew install mpv&#39;
# imagemagick
execute &#39;brew install imagemagick --with-fontconfig --with-ghostscript--with-jp2 --with-librsvg --with-libtiff --with-webp&#39;
# reinstall a more colorful emacs
execute &#39;brew reinstall emacs --cocoa --srgb --with-d-bus --with-gnutls --with-imagemagick --with-librsvg --with-mailutils&#39;
# bash
execute &#39;brew install bash&#39;
# curl
execute &#39;brew install curl --with-gssapi --with-idn --with-ssh&#39;
prefix=$(latest_bin curl)
execute &quot;ln -s ${prefix}/curl ${HOME}/bin&quot;

########## other stuff ##########
# brew-desc
execute &#39;brew tap telemachus/desc&#39;
execute &#39;brew install brew-desc&#39;
# bzr
execute &#39;brew install bzr&#39;
# chrome-cli
execute &#39;brew install chrome-cli&#39;
# dos2unix
execute &#39;brew install dos2unix&#39;
# exiftool
execute &#39;brew install exiftool&#39;
# fdupes
execute &#39;brew install fdupes&#39;
# htop
execute &#39;brew install htop-osx&#39;
# htop requires root priviledge; put it off to the end so that automatic install is not interrupted
# jq
execute &#39;brew install jq&#39;
# libmagic
execute &#39;brew install libmagic --with-python&#39;
# man2html
execute &#39;brew install man2html&#39;
# mercurial
execute &#39;brew install mercurial&#39;
# moreutils
execute &#39;brew install moreutils --without-parallel&#39;
# most
execute &#39;brew install most&#39;
# npm
execute &#39;brew install npm&#39;
# p7zip
execute &#39;brew install p7zip&#39;
# parallel
execute &#39;brew install parallel&#39;
# rar
execute &#39;brew install rar&#39;
# re2c
execute &#39;brew install re2c&#39;
# rsync
execute &#39;brew install rsync&#39;
# terminal-notifier
execute &#39;brew install terminal-notifier&#39;
# tmux
execute &#39;brew install tmux&#39;
execute &#39;brew install reattach-to-user-namespace&#39;
# vim
execute &#39;brew install vim --override-system-vi&#39;
# xz
execute &#39;brew install xz&#39;
# yasm
execute &#39;brew install yasm&#39;
# youtube-dl
execute &#39;brew install youtube-dl&#39;
# zsh-completions
execute &#39;brew install zsh-completions&#39;

# link apps
execute &#39;brew linkapps&#39;

# grant htop root priviledge
prefix=$(latest_bin htop-osx)
execute &quot;sudo chown root:wheel ${prefix}/htop &amp;&amp; sudo chmod u+s ${prefix}/htop&quot;

echo -n &quot;${caveats}&quot; &gt;&amp;2
</code></pre></noscript></div>



]]></content>
  </entry>
  
</feed>
